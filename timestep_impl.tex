%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Pseudo-Code}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The algorithm in the time stepping are quite simple, however their implementation can be very difficult to understand and reason about. To make it easier to understand to understand implementation, the core routines are presented here in a high-level pseudo code similar to Julia. Many variables, type names, and functions have been renamed to make their meaning clearer. For example \lst{_nt} has been renamed \lst{cell_group}, to clearly identify its meaning.

An example of the pseudo code represents the following C code
\begin{inlinelisting}{C++}{current C mechanism loop}{lst:cmechloop}
for (tml = _nt->tml; tml; tml = tml->next)
  if (memb_func[tml->index].current) {
    mod_f_t s = memb_func[tml->index].current;
    (*s)(_nt, tml->ml, tml->index);
  }
\end{inlinelisting}
\noindent as
\begin{inlinelisting}{julia}{julia mechanism loop}{lst:juliamechloop}
for mechanism in cell_group.mechanisms
  current(mechanism)
end
\end{inlinelisting}

\noindent Note that the same level of clarity is possible with C+11:
\begin{inlinelisting}{julia}{C++11 mechanism loop}{lst:cppmechloop}
for( auto &mechanism : cell_group.mechanisms() ) {
  mechanism.current();
}
\end{inlinelisting}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Data}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The data layout in the \neuron code is described in more detail in \sect{sec:data}. For this part of the report, we use a representation of the storage for a group of cells that is easier to understand.

\neuron stores \emph{cell groups}, which are a set of cells, in a \lst{NrnThread} data structure. The ``thread'' in the type name is misleading, so it is renamed as a \lst{CellGroup} in \lstref{lst:juliacellgroup}.

\begin{inlinelisting}{julia}{cell group data structure}{lst:juliacellgroup}
# storage for a group of cells packed into flat arrays
type CellGroup
  Int ncells    # number of cells in group
  Int nnodes    # total number of nodes in all cells

  Array{Int} parent_indices

  # list of all the mechanisms for this cell group
  Array{Any} mechanisms

  # storage for the linear system
  Array{Float} VEC_A
  Array{Float} VEC_B
  Array{Float} VEC_D
  Array{Float} VEC_V
  Array{Float} VEC_RHS
end
\end{inlinelisting}

The other important abstraction is a \emph{mechanism}. In the definition of \lst{CellGroup}, there is an array called \lst{mechanisms}. Loosley defined, mechanisms are processes that occur at nodes \footnote{This is generally true. There are some exceptions, but we ignore those for now.}, for example a mechanism might define the state of a synapse at a node.

The same mechanism can be applied to more than one nodes in a cell group, e.g. the same synapse type might be present at many different nodes. Pseudo code for a type that stores the information required to define a mechanism for a cell group is in \lstref{lst:juliamechanism}.  There are three important sets of information for the mechanism type:
\begin{enumerate}
    \item
        Information about which nodes the mechanism is to be applied at, i.e. \lst{nodecount} and \lst{nodeindices}.
    \item
        State information for the mechanism at every node at which it is applied. For example, synapses are modelled with an ordinary differential equation for current, which has multiple fields and parameters. The value of each field and parameter has to be stored at each node. In the example used here this is stored as a structure of array (SoA) format, with one vector of length \lst{nodecount} for each state parameter/variable.
    \item
        External Ion information.
        Some mechanisms read/write to the state of ion chanels, which are implemented as separate mechanisms.
        A method for reading/writing the state of another mechanism is required, which we have abstracted with the Ion type, which can be considered to be a reference to the state information stored in the appropriate ion mechanism.
\end{enumerate}

\begin{inlinelisting}{julia}{calcium mechanism data structure}{lst:juliamechanism}
# mechanism for calcium
type CaMechanism
  Int        nodecount   # number of nodes with this mechanism
  Array{Int} nodeindices # indices of nodes with this mechanism

  # data fields for every node at which mechanism is applied
  # implemented as a private data type
  type Data
    Array{Float} gCabar
    Array{Float} ica
    Array{Float} gCa
    Array{Float} m
    Array{Float} h
    # ...
  end
  Data data

  # storage for ion channels
  type Ion
    Array{Float} ica
    Array{Float} eca
    Array{Float} icadv
  end
  Ion ion
end

# specialize functions for calcium mechanism
function current(mechanism::CaMechanism)
    # implementation goes here
end
function jacob(mechanism::CaMechanism)
    # implementation goes here
end
function state(mechanism::CaMechanism)
    # implementation goes here
end
\end{inlinelisting}

\begin{note}
The description of interactions with ion mechanisms is a gross simplification of how ion interactions are handled: \emph{it's complicated, and I do not understand it yet}.
The treatment of ionic processes varies from node to node, and depends on the combination of mechanisms on the node.
I have a feeling that finding a generic and performant method for handling ion channel interactions will be the trickiest part of optimizing the computational engine.
\end{note}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{One Time Step}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The inner part of each time step is implemented in the function \lst{nrn_fixed_step_thread}, in \file{nrnoc/fadvance_core.c}. The routine takes as its argument a pointer to a struct of type \lst{NrnThread}. Here we implement it with a \lst{CellGroup} argument as defined in \lstref{lst:juliacellgroup}.

%*******************************************************************************
\filelisting [julia] {./code/fixed_step_thread.jl}{one time step}{lst:fixedstepthread}
%*******************************************************************************

%*******************************************************************************
\begin{figure}[htp!]
\centering
\includegraphics[width=0.75\textwidth]{./images/timestep_flow.pdf}
\caption{Description of a single time step.}
\label{fig:timestepDiagram}
\end{figure}
%*******************************************************************************

%*******************************************************************************
\begin{figure}[htp!]
\centering
\includegraphics[width=\textwidth]{./images/calltree.pdf}
\caption{Calltree and percentage of wall time contribution for the main computational algorithm. Branches marked in blue indicate a significant contribution to wall time.}
\label{fig:calltree}
\end{figure}
%*******************************************************************************

A breakdown of wall time for the steps in \lst{nrn_fixed_step} is given in \fig{fig:calltree}. Some of the routines listed here have less than 1\% of wall time (including the linear system solve in \lst{nrn_solve_minimal}), however they are discussed below because their data access influence the implementation on many-core architectures (e.g. GPU and MIC).
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Building matrix and RHS: \lst{setup_tree_matrix}}
\label{sec:matrix_rhs}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The function \lst{setup_tree_matrix} generates the diagonal, the $d_i$ values, and the RHS vector. These tasks are performed in two separate routines, \lst{nrn_lhs} and \lst{nrn_rhs}.
\filelisting[julia]{./code/setup_tree_matrix.jl}{forming diagonal and right hand side of linear system}{lst:setuptreematrix}

The \lst{nrn_lhs} function sets the values on the diagonal of the matrix, stored in \lst{VEC_D}. It starts by initializing the \lst{VEC_D} to zero, the calls the \lst{jacob} function for each mechanism. The \lst{jacob} function adds the conrtibution from each mechanism at each node to the relevant entry in \lst{VEC_D}.
The \lst{jacob} funtion is defined for each mechanism that contributes to the diagonal.
The \lst{jacob} functions are identical for all such mechanisms, except for the capacitance mechanism, which is always the first mechanism \lst{thread.mechanisms[1]}.
Both forms are shown below:

\filelisting[julia]{code/jacob.jl}{updating the diagonal}{lst:update}

It is common for multiple mechanisms to be defined on the same node (indeed, often there are many instances of the same mechanism on a single node). As such, it is not possible to replace for loop over the mechanisms that calls the \lst{current} function with a \lst{parallel_forall} loop, because there will be race conditions if different mechansims update the same \lst{VEC_RHS} values simultaneously.

\begin{note}
A big challenge in fine-grained parallelism of the time step will always boild down to avoiding such race conditions. It may be possible to work around this issue using \emph{ghost arrays} for each mechanism, into which \lst{VEC_*} arrays are gatherd, or from which they are scattered, before or after looping over a mechanism operation.
\end{note}

The \lst{current} functions for the mechanisms contribute 45\% of time to solution for the TEST2 benchmark. An  example of a \lst{current} implementation is given below (specifically, it is the mechanism defined in \file{/mech/cfiles/NaTa_t.c}). Note that it uses references to .

\filelisting [julia] {./code/current.jl}{calculating the current \& updating the right hand side}{lst:current}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Solving the linear system: \lst{nrn_solve_minimal}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The solution of the linear system using Hines algorithm is straight forward, and is implemented in \file{/nrnoc/solve_core.c}. As described in \sect{sec:hines}, the upper triangle is eliminated first with a backward sweep, followed by a forward sweep, which differs from the usual presentation of Gaussian elimination as a forward substitution followed by backwards substitution.

\filelisting [julia] {./code/nrn_solve_minimal.jl}{solving the linear system}{lst:solveminimal}

\begin{note}
The solution is applied to all of the cells in a \lst{CellGroup} in one sweep.
However, the linear systems for the cells are independent, so this can be parallelized by solving for all trees simultaneously, though it would require additional metadata not present in the current \lst{CellGroup} representation.

All of the nodes in the cell group are numbered such that the root node for all of the trees are numbered \lst{1:ncells}, so that for example the values in \lst{VEC_D[1:ncells]} correspond to the diagonal values on the first row of the matrix of cells \lst{1:ncells}.
This is evident when we look at the last step in the backward substituion, where only the value in row 1 of the RHS vector is scaled by the diagonal.
Instead of being applied to just \lst{VEC_RHS[1]}, it is applied to \lst{VECH_RHS[1:ncells]}.
\end{note}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Advancing the solution: \lst{update}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
These routines have almost no computational overhead, but they are included here to record their data access patterns.
The solution to the linear system, stored in \lst{VEC_RHS} is actually the delta in solution, that is $\at{\text{RHS}} = \at{V}^{n+1} - \at{V}^{n}$.
The \lst{update} function updates the solution in \lst{VEC_V} by adding the contribution in \lst{VEC_RHS}.
The \lst{update} function is the only part of the \neuron code that successfully vectorizes, because of the stride-one data access pattern in the update.

The \lst{second_order_cur} routine is used to ensure that current is up to date for ion channels before the solution update is applied, in case they are required for reporting, i.e. the results are not used in the solution.

The \lst{nrn_capacity_current} calculates the current for the capacitance mechanism (which is always the first mechanism). This needs to be updated here, as opposed to when the currents are updated for all the other mechanisms in \lst{nrn_rhs} in \sect{sec:matrix_rhs}.

\filelisting [julia] {./code/update.jl}{updating the solution}{lst:update}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Updating \emph{state}: \lst{nonvint}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The \lst{nonvint} function is a simple lookup of the \lst{state} function defined for each mechanism. These calls are a significant contribution to computational overheads -- greater than 40\% for the TEST2 benchmark.

\filelisting [julia] {./code/nonvint.jl}{non voltage integration}{lst:nonvint}

The \lst{state} function implementations are derived from the \hoc implementation, and are specialized for each mechanism type. These have obvious potential for vectorization, because they are often compuationally intensive with expensive operations like \lst{exp} and \lst{pow}. Below is an example of one state update, note the many exponentials (some of which are redundant, i.e. no attempt is made to take advantage of identities like $\text{e}^{-x}=1/\text{e}^{x}$)

\filelisting [julia] {./code/state.jl}{integrating the currents}{lst:state}

\begin{note}
    The \lst{state}, \lst{current} and \lst{jacob} functions are defined uniquely for each mechanism type. Not all mechansims have require all of these functions, in which case calling one of these functions on that mechanism type does nothing. In practice \neuron implements this by checking the value of a function pointer, and only calls it if the pointer is not \lst{NULL}.
\end{note}
