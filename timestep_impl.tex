In this section the implementation of the code that forms and solves the matrix, which accounts for 99\% of the time to solution will be described. The algorithm themselves are quite simple, however their implementation is very difficult to understand. To make it easier to understand to understand implementation, the core routines have been rewritten in a high-level pseudo code similar to Julia.

An example of the pseudo code represents the following C code
\begin{shaded}
\begin{lstlisting} [language=C,breaklines=true]
for (tml = _nt->tml; tml; tml = tml->next)
  if (memb_func[tml->index].current) {
    mod_f_t s = memb_func[tml->index].current;
    (*s)(_nt, tml->ml, tml->index);
  }
\end{lstlisting}
\end{shaded}
\noindent as
\begin{shaded}
\begin{lstlisting} [language=julia,breaklines=true]
for mechanism in thread.mechanisms
  current(mechanism)
end
\end{lstlisting}
\end{shaded}
\noindent Note that a similar level of clarity would be possible with well-designed C+11 code:
\begin{shaded}
\begin{lstlisting} [language=julia,breaklines=true]
for( auto &mechanism : thread.mechanisms() ) {
  mechanism.current(thread);
}
\end{lstlisting}
\end{shaded}

The inner part of each time step is implemented in the function \lst{nrn_fixed_step_thread()}, in \file{nrnoc/fadvance_core.c}. The routine takes as its argument a pointer to a struct of type \lst{NrnThread}, see \fig{lst:NrnThread}, which holds state relating to a set of cells to be integrated in time.
\begin{shaded}
\lstinputlisting [language=julia,breaklines=true] {./code/fixed_step_thread.jl}
\end{shaded}

A breakdown of wall time for the steps in \lst{nrn_fixed_step()} is given in \fig{fig:calltree}. Some of the routines listed here have less than 1\% of wall time (including the linear system solve in \lst{nrn_solve_minimal()}), however they are discussed below because they access they have implementation details that will influence the implementation on many-core architectures (e.g. GPU and MIC).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Building matrix and RHS: \lst{setup_tree_matrix()}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The function \lst{setup_tree_matrix()} generates the diagonal, the $d_i$ values, and the RHS vector. These tasks are performed in two separate routines, \lst{nrn_lhs()} and \lst{nrn_rhs()}.
\begin{shaded}
\lstinputlisting [language=julia,breaklines=true] {./code/setup_tree_matrix.jl}
\end{shaded}

Points
\begin{itemize}
\item
    The array \lst{p} is an index array containing the parent node indexes.
\item
    The arrays \lst{VEC_*} correspond to the vectors $\vv{a}, \vv{b}, \vv{d}, \vv{v}, \vv{r}$ that define the linear system.
\item
    Each thread has multiple cells, each with their own tree representation. The cells are packed together, with the root node of each cell placed first in the list of all nodes, hence the definition of \lst{child_nodes} excluding indexes $1:ncells$.
\item
    Nearly all (i.e. 99\%) of the time in these two routines is spent in the calls to the \lst{mechanism.current()} and \lst{mechanism.jacob()} routines.
\item
    The matrix updates still must be considered, because there are potential race conditions in a multi-threaded/GPU implementation. For example the statement \\ \lst{VEC_RHS[p[i]] += dv * VEC_A[i]} \\ will lead to a race condition if two threads with the same parent node try to update the RHS vector at the same time.
\end{itemize}

The \lst{mechanism.current()} and \lst{mechanism.jacob()} routines are defined in the \file{/mech/cfiles} path, and are automatically generated from Neuron hoc DSL. \fig{fig:calltree} shows that all of the computational work in the \neuron benchmark used in this report is performed by functions from the hoc layer. The \lst{jacob} functions are also very simple, and all have the same form \hilight{(I think, there may be some exceptions)}
\begin{shaded}
\lstinputlisting [language=julia,breaklines=true] {./code/jacob.jl}
\end{shaded}

The \lst{mechanism.current} calls contribute 45\% of time to solution for the TEST2 benchmark. They are uniquely defined for each mechanism. \hilight{Is it possible to present a few different examples that have all the expected \emph{patterns} in a current implementation?}. A ``representative'' example of a \lst{current} implementation is:
\begin{shaded}
\lstinputlisting [language=julia,breaklines=true] {./code/current.jl}
\end{shaded}
\hilight{I don't understand the \lst{ppvar} variable, and how it is used to implement lookups like \lst{_ion_dinadv}. Any insight here would be appreciated.}

The \lst{nrn_cap_jacob()} function is a very simple, illustrating a common data access pattern whereby a vector (int this case \lst{VEC_D}) is updated according to the parent node if the loop index:
\begin{shaded}
\lstinputlisting [language=julia,breaklines=true] {./code/nrn_cap_jacob.jl}
\end{shaded}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Solving the linear system: \lst{nrn_solve_minimal()}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The solution of the linear system using Hines algorithm is straightforward, and is implemented in \file{/nrnoc/solve_core.c}.

\begin{shaded}
\lstinputlisting [language=julia,breaklines=true] {./code/nrn_solve_minimal.jl}
\end{shaded}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Advancing the solution: \lst{update()}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

These routines have almost no computational overhead, and are included here for completeness.

The solution to the linear system, stored in \lst{VEC_RHS} is actually the delta in solution, that is $\at{\text{RHS}} = \at{V}^{n+1} - \at{V}^{n}$. The \lst{update()} function updates the solution in \lst{VEC_V} by adding the contribution in \lst{VEC_RHS}. The \lst{update()} function is the only part of the \neuron code that successfully vectorizes, because of the stride-one data access pattern in the update.

\hilight{I don't know the purpose of the \lst{second_order_cur()} and \lst{nrn_capacity_current()} routines.}

\begin{shaded}
\lstinputlisting [language=julia,breaklines=true] {./code/update.jl}
\end{shaded}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Updating \emph{state}: \lst{nonvint()}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The \lst{nonvint()} function is a simple lookup of the \lst{state()} function defined for each mechanism. These calls are a significant contribution to computational overheads -- greater than 40\% for the TEST2 benchmark.

\begin{shaded}
\lstinputlisting [language=julia,breaklines=true] {./code/nonvint.jl}
\end{shaded}

The \lst{state()} function implementations are derived from the \file{.hoc} implementation. These have obvious potential for vectorization, because they do not appear to have the ``parent update'' pattern in other loops. However this would require using structore of array (SoA) storage (see the next section). Below is an example of one state update -- note the many exponentials (some of which are redundant, i.e. )

\begin{shaded}
\lstinputlisting [language=julia,breaklines=true] {./code/state.jl}
\end{shaded}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Data Layout}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
High level overview of cell distribution across ranks and threads.
\begin{itemize}
\item
    There are cells, where each cell consists of a tree of nodes.
\item
    There are two levels of parallelism:
    \begin{enumerate}
    \item
        \textbf{MPI}: the cells are distributed between MPI ranks.
    \item
        \textbf{thread}: the cells on each MPI rank are further subdivided between threads.
    \end{enumerate}
\item
    Each thread stores the cells assigned to it in a \lst{NrnThread} data structure (see \fig{lst:NrnThread})
\item
    There is one \lst{NrnThread} data structure for each thread.
\item
    Threading is performed using pthreads, with explicit communication of spike information between threads and between MPI processes.
\end{itemize}

\noindent
Overview of storage of cells in one thread:
\begin{itemize}
\item
    Each thread has multiple cells assigned to it.
\item
    For the TEST2 dataset:
    \begin{itemize}
    \item
        there are around 60--70 cells per thread.
    \item
        each cell has of the order 400--450 nodes.
    \item
        each thread has 25,000--30,000 nodes.
    \end{itemize}
\item
    The nodes for all cells are stored in one flat array
    \begin{itemize}
    \item
        Given have $n_c$ cells and a total of $n$ nodes, the root nodes are indexed \lst{[1:n_c]}, and the rest of the nodes are indexed \lst{[n_c+1:n]}.
    \item
        This is evident in the loops over \lst{child_nodes=ncells+1:nnondes} and \lst{1:ncells}
    \end{itemize}
\end{itemize}

\noindent
Mechanisms in Neuron are implemented using the \lst{hoc} DSL, which is translated into C code.
\neuron has the C files allready translated from the \hoc files that are used by BBP\footnote{This reduces the complexity of \neuron, decoupling \neuron from Neuron, which will make it easier modify how the mechanisms are defined.}.
The translated mechanism definitions are in \file{mech/cfiles}, with one mechanism per C source file.
Each file defines functions (like \lst{jacob}, \lst{current}, \lst{alloc}) and meta-data (such as the number of variables required to store a mechanism's state for a node in the tree).
\begin{itemize}
\item
    The mechanism data is stored in global two arrays: \lst{Memb_list memb_list[]} and \lst{Memb_func memb_func[]}.
    \begin{enumerate}
    \item
        The \lst{Memb_func} type has function pointers to the \lst{jacob}, \lst{current}, \lst{state} and other mechanism-specific functions, and other meta-data specific to the mechanism.
    \item
        The \lst{Memb_list} has a pointer to the per-node data, and a list of all the nodes that the mechanism is defined for.
    \end{enumerate}
\item
    The implementation of a mechanism in \lst{mech/cfiles} provides has a function \lst{??} that calls the \lst{register_mech()} function, which adds the mechanisms function callbacks for \lst{jacob} etc, along with meta-data into the global arrays (see \fig{lst:register_mech}).
\item
    Each thread has a list of mechanisms assigned to it, which are accessed via a linked list \lst{NrnThread::mechanisms} (see \fig{lst:NrnThreadInfo} where I have changed the name \lst{tml} to \lst{mechanisms}, to better match the pseudo code.) The linked list indexes the global arrays \lst{memb_list} and \lst{memb_func} \hilight{(why not use an array instead of a linked list?)}.
\item
    There are many opportunities to improve the interface between the runtime (solvers etc) and user-defined mechanisms.
    This model is well-suited to standard object-oriented design.
    Furthermore, much of the meta-data that is currently passed as runtime parameters could be stored as type-information that could help the compiler optimize more agressively.
\end{itemize}

\noindent
Mechanisms and their storage:
\begin{itemize}
\item
    All mechanisms are not applied to different nodes. For example, the \lst{ProbAMPANDMDA_EMS} mechanism will only be applied at a subset of the nodes in a cell.
\item
    Each mechanism has ``state'' that is stored for each node to which it is applied. This state is a set of double-precision values (e.g. a set of values describing the time evolution of a ordinary differential equation).
\item
    The number of state variables varies between mechanisms, ranging from 3 to 35 values.
\item
    Each entry in \lst{memb_list[]} stores 
    \begin{itemize}
    \item
        \lst{int nodecount}: the number of nodes to which
    \item
        \lst{int nodeindices[nodecount]}: the indexes of the nodes to which the mechanism is to be applied.
    \item
        \lst{double data[nodecount*var_per_node]}: AoS storage for the mechanism  values.
    \end{itemize}
\end{itemize}


\begin{figure}
\begin{shaded}
\lstinputlisting [language=C++,breaklines=true] {./code/storage.cpp}
\end{shaded}
\label{lst:NrnThreadInfo}
\caption{The thread (\lst{NrnThread}), mechanism data (\lst{Memb_list}) and mechanism functionality (\lst{Memb_func}) types. I have removed and renamed much of the members to make them better match the pseudo code. Some C++ coding style has also been used.}
\end{figure}

\begin{figure}
\begin{shaded}
\lstinputlisting [language=C++,breaklines=true] {./code/register_mech.cpp}
\end{shaded}
\label{lst:register_mech}
\caption{The routines used in registering a mechanism}
\end{figure}

\begin{figure}[htp!]
\input{images/AoSvsSoA.tex}
\caption{The current AoS layout of mechanism parameters for all applicable nodes.}
\end{figure}

\noindent
Observations
\begin{itemize}
\item
    Splitting the cells into seperate, thread-specific, data structures complicates the code. This feels like it was added at some point to facilicate threading.
\item
    Could be stripped away, to store all cells on a node/numa-region/device into a single pool.
\item
    The AoS storage is inefficient:
    \begin{itemize}
    \item
        It doesn't vectorize (see \fig{fig:papisample}).
    \item
        Very poor cache/bandwidth utlization for loops (such as the \lst{jacob} update) where only one or two data values in a mechanism are touched. For each 64 byte cache line loaded, only 8 bytes of 64 are used.
    \end{itemize}
    An SoA storage would address both issues.
\item
    With SoA vectorization of most loops would still not be possible, because of the gather/scatter implicit in using the node indexes to read/write to the V and RHS vectors.
    \begin{itemize}
    \item
        Perform scatter before computing the current, then gather after.
    \end{itemize}
\end{itemize}
